{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              person_id_syn  transportation_issues src_platform_cd sex_cd  \\\n",
       "0  0002MOb79ST17bLYAe46eIc2                      0              EM      F   \n",
       "1  0004cMOS6bTLf34Y7AIca8f3                      0              EM      F   \n",
       "2  000536M9O3ST98LaYaeA29Ia                      1              EM      F   \n",
       "3  0009bMO9SfTLYe77A51I4ac3                      0              EM      M   \n",
       "4  000M7OeS66bTL8bY89Aa16Ie                      0              EM      M   \n",
       "\n",
       "   est_age  smoker_current_ind  smoker_former_ind lang_spoken_cd mabh_seg  \\\n",
       "0       62                   1                  0            ENG      UNK   \n",
       "1       59                   1                  0            ENG       C2   \n",
       "2       63                   0                  0            ENG      UNK   \n",
       "3       75                   0                  0            ENG       H6   \n",
       "4       51                   1                  0            ENG      UNK   \n",
       "\n",
       "   cci_score  ...  submcc_rar_scl_ind  rx_gpi2_74_ind  rx_gpi2_89_ind  \\\n",
       "0        3.0  ...                   0               0               0   \n",
       "1        1.0  ...                   0               0               0   \n",
       "2        3.0  ...                   0               0               0   \n",
       "3        3.0  ...                   0               0               0   \n",
       "4        3.0  ...                   0               0               0   \n",
       "\n",
       "   rx_gpi2_96_ind  submcc_rsk_obe_ind  rx_gpi2_22_ind  submcc_rsk_synx_ind  \\\n",
       "0               0                   0               0                    0   \n",
       "1               0                   1               0                    0   \n",
       "2               0                   0               0                    0   \n",
       "3               0                   1               0                    0   \n",
       "4               0                   0               0                    0   \n",
       "\n",
       "   submcc_rsk_coag_ind  submcc_rsk_othr_ind  submcc_rsk_chol_ind  \n",
       "0                    0                    0                    0  \n",
       "1                    0                    0                    1  \n",
       "2                    0                    0                    1  \n",
       "3                    0                    0                    1  \n",
       "4                    0                    0                    1  \n",
       "\n",
       "[5 rows x 826 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>person_id_syn</th>\n      <th>transportation_issues</th>\n      <th>src_platform_cd</th>\n      <th>sex_cd</th>\n      <th>est_age</th>\n      <th>smoker_current_ind</th>\n      <th>smoker_former_ind</th>\n      <th>lang_spoken_cd</th>\n      <th>mabh_seg</th>\n      <th>cci_score</th>\n      <th>...</th>\n      <th>submcc_rar_scl_ind</th>\n      <th>rx_gpi2_74_ind</th>\n      <th>rx_gpi2_89_ind</th>\n      <th>rx_gpi2_96_ind</th>\n      <th>submcc_rsk_obe_ind</th>\n      <th>rx_gpi2_22_ind</th>\n      <th>submcc_rsk_synx_ind</th>\n      <th>submcc_rsk_coag_ind</th>\n      <th>submcc_rsk_othr_ind</th>\n      <th>submcc_rsk_chol_ind</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0002MOb79ST17bLYAe46eIc2</td>\n      <td>0</td>\n      <td>EM</td>\n      <td>F</td>\n      <td>62</td>\n      <td>1</td>\n      <td>0</td>\n      <td>ENG</td>\n      <td>UNK</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0004cMOS6bTLf34Y7AIca8f3</td>\n      <td>0</td>\n      <td>EM</td>\n      <td>F</td>\n      <td>59</td>\n      <td>1</td>\n      <td>0</td>\n      <td>ENG</td>\n      <td>C2</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000536M9O3ST98LaYaeA29Ia</td>\n      <td>1</td>\n      <td>EM</td>\n      <td>F</td>\n      <td>63</td>\n      <td>0</td>\n      <td>0</td>\n      <td>ENG</td>\n      <td>UNK</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0009bMO9SfTLYe77A51I4ac3</td>\n      <td>0</td>\n      <td>EM</td>\n      <td>M</td>\n      <td>75</td>\n      <td>0</td>\n      <td>0</td>\n      <td>ENG</td>\n      <td>H6</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000M7OeS66bTL8bY89Aa16Ie</td>\n      <td>0</td>\n      <td>EM</td>\n      <td>M</td>\n      <td>51</td>\n      <td>1</td>\n      <td>0</td>\n      <td>ENG</td>\n      <td>UNK</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 826 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('/Users/chiufengyap/OneDrive - The University of Texas Health Science Center at Houston/Humana_Mays_2020/2020_Competition_Training.csv', chunksize=10000)\n",
    "df = df.read()\n",
    "df = df.reindex()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['transportation_issues']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['zip_cd','person_id_syn'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#get categorical feautes and convert all values to string\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "print(categorical_features)\n",
    "df.loc[:,categorical_features].astype(str)\n",
    "\n",
    "cat = SimpleImputer(strategy='most_frequent',copy=False)\n",
    "cat1 = cat.fit(df[categorical_features].astype(str))\n",
    "df[categorical_features] = cat1.transform(df[categorical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute numeric\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "num = SimpleImputer(strategy='median',copy=False)\n",
    "num1 = num.fit(df[numeric_features])\n",
    "df[numeric_features] = num1.transform(df[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dummies on all categorical variables to create new numerical columns, then drop original columns\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "X = pd.get_dummies(df[categorical_features], prefix_sep='_')\n",
    "X = pd.merge(df,X,how='outer',left_index=True,right_index=True)\n",
    "X = X.drop(categorical_features, axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary indicator for values > 75 percentile, and sqrt to amplify values\n",
    "X['med_er_visit_high'] = np.where(X['med_er_visit_ct_pmpm'] > 0.1, 1, 0)\n",
    "\n",
    "#binary indicator for values > 75 percentile, and sqrt to amplify values\n",
    "X['total_er_visit_high'] = np.where(X['total_er_visit_ct_pmpm'] > 0.1, 1, 0)\n",
    "\n",
    "X['med_plus_total_er_visit'] = X['med_er_visit_ct_pmpm'] + X['total_er_visit_ct_pmpm']\n",
    "\n",
    "#combine codes for superficial injuries (likely falls)\n",
    "#X['ccsp_236_239'] = X['ccsp_239_ind'] + X['ccsp_236_ind']\n",
    "\n",
    "#combine low income indicators and square/cube to amplify\n",
    "#X['low_inc'] = X['cms_dual_eligible_ind'] + X['cms_low_income_ind']\n",
    "\n",
    "#combine behavioral health indicators and square/cube\n",
    "#X['bh_tot'] = X['bh_cdto_ind'] + X['bh_bipr_ind'] + X['bh_dema_ind'] + X['bh_cdsb_ind'] + X['bh_aoth_ind']\n",
    "\n",
    "#create binary column for high risk cms part d (anything above 75 percentile considered high risk)\n",
    "X['cms_partd_high_risk'] = np.where(X['cms_partd_ra_factor_amt'] > 1.32, 1, 0)\n",
    "\n",
    "#create binary column for high risk cms ma (anything above 75 percentile considered high risk)\n",
    "X['cms_ma_high_risk'] = np.where(X['cms_ma_risk_score_nbr'] > 1.34, 1, 0)\n",
    "\n",
    "#amplify correlated cms risk/payment amounts by squaring and cubing values\n",
    "X['cms_tot_ma_payment_amt_sqrt'] = np.sqrt(X['cms_tot_ma_payment_amt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional features\n",
    "\n",
    "# low_inc                                 154.072680\n",
    "# est_age                                 119.421419\n",
    "# ccsp_236_239                             80.907964\n",
    "# cms_tot_partd_payment_amt                78.778600\n",
    "# med_ambulance_visit_ct_pmpm              62.059773\n",
    "# total_ambulance_visit_ct_pmpm            52.921809\n",
    "# cms_rx_risk_score_nbr                    50.098201\n",
    "# cms_disabled_ind                         48.187203\n",
    "# bh_tot                                   47.511346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of our conditions\n",
    "conditions = [\n",
    "    (X['cms_rx_risk_score_nbr'] >= 1.84),\n",
    "    (X['cms_rx_risk_score_nbr'] >= 1.04) & (X['cms_rx_risk_score_nbr'] <= 1.84),\n",
    "    (X['cms_rx_risk_score_nbr'] >= 0.24) & (X['cms_rx_risk_score_nbr'] <= 1.04),\n",
    "    (X['cms_rx_risk_score_nbr'] >= 0) & (X['cms_rx_risk_score_nbr'] <= 0.24),\n",
    "    ]\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = [4,3,2,1]\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "X['cms_rx_risk_score_grp'] = np.select(conditions, values)\n",
    "# display updated DataFrame\n",
    "X['cms_rx_risk_score_grp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['cms_rx_risk_score_hi'] = np.where(X['cms_rx_risk_score_nbr'] > 1.83, 1, 0)\n",
    "X['cms_rx_risk_score_hi'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X['age_90plus'] = np.where(X['est_age'] > 89, 1, 0)\n",
    "X['age_80to90'] = np.where((X['est_age'] > 79) & (X['est_age'] < 90) , 1, 0)\n",
    "X['age_70to80'] = np.where((X['est_age'] > 69) & (X['est_age'] < 80) , 1, 0)\n",
    "X['age_60to70'] = np.where((X['est_age'] > 59) & (X['est_age'] < 70) , 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X['cms_tot_partd_payment_hi'] = np.where(X['cms_tot_partd_payment_amt'] > 243, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['med_ambulance_visit_ct_hi'] = np.where(X['med_ambulance_visit_ct_pmpm'] > .08, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['total_ambulance_visit_ct_hi'] = np.where(X['total_ambulance_visit_ct_pmpm'] > .08, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['tot_ambulance_visit_pmpm'] = X['total_ambulance_visit_ct_pmpm'] + X['med_ambulance_visit_ct_pmpm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[lim_cols]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['y'] = y\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "clf = IsolationForest(random_state=0).fit(X)\n",
    "\n",
    "outliers = clf.fit_predict(X)\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(outliers), len(outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['outliers'] = outliers\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe for outliers\n",
    "X_out =  X[X['outliers'] == -1]\n",
    "X_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outliers from main dataframe\n",
    "X = X[X['outliers'] == 1].drop('outliers',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering with featuretools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft\n",
    "\n",
    "# Create Entity\n",
    "entity = X.reindex(sorted(X.columns), axis=1)\n",
    "entity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betos = entity.iloc[:,0:13]\n",
    "betos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = ft.EntitySet(id = 'clients')\n",
    "es = es.entity_from_dataframe(entity_id = 'X', dataframe = entity, \n",
    "                              make_index = True, index='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es.entity_from_dataframe(entity_id = 'betos', dataframe = betos, \n",
    "                              index='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run deep feature synthesis with transformation primitives\n",
    "feature_matrix, feature_defs = ft.dfs(entityset = es, target_entity = 'betos',\n",
    "                                      max_depth = 2, \n",
    "                                      verbose = 1, \n",
    "                                      n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = ft.EntitySet(id = 'Turnover')\n",
    "es.entity_from_dataframe(entity_id = 'betos', dataframe = betos, index = 'index')\n",
    "\n",
    "# Run deep feature synthesis with transformation primitives\n",
    "feature_matrix, feature_defs = ft.dfs(entityset = es, target_entity = 'betos',\n",
    "                                      trans_primitives = ['add_numeric', 'percentile'], \n",
    "                                      verbose=True, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ft.list_primitives()\n",
    "f[30:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(X,feature_matrix,how='outer',left_index=True,right_index=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['y'] = y\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, X.iloc[:,-1], test_size = 0.20,random_state = 12)\n",
    "print(len(X_Train), len(Y_Train), len(X_Test), len(Y_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use only after limiting columns based on featuree importance for next step\n",
    "X_Train = pd.merge(Y_Train, X_Train, how='outer', left_index=True, right_index=True)\n",
    "X_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test = X_Test.drop('transportation_issues',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bagging xgboost process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random undersampling\n",
    "#tomek undersampling\n",
    "#fit xgb models and make predictions\n",
    "#bagging classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random sampling with replacement only on majority class\n",
    "import random\n",
    "\n",
    "X_Train_0 = X_Train[X_Train['y'] == 0]\n",
    "X_Train_1 = X_Train[X_Train['y'] == 1]\n",
    "\n",
    "print(X_Train_0.shape, X_Train_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create random samples of majority class\n",
    "X_Train_0_1 = X_Train_0.sample(12285)\n",
    "X_Train_0_2 = X_Train_0.sample(12285)\n",
    "X_Train_0_3 = X_Train_0.sample(12285)\n",
    "X_Train_0_4 = X_Train_0.sample(12285)\n",
    "X_Train_0_5 = X_Train_0.sample(12285)\n",
    "X_Train_0_6 = X_Train_0.sample(12285)\n",
    "X_Train_0_7 = X_Train_0.sample(12285)\n",
    "X_Train_0_8 = X_Train_0.sample(12285)\n",
    "X_Train_0_9 = X_Train_0.sample(12285)\n",
    "X_Train_0_10 = X_Train_0.sample(12285)\n",
    "X_Train_0_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine above with minority class\n",
    "X_Train_samp1 = pd.concat([X_Train_0_1, X_Train_1])\n",
    "X_Train_samp2 = pd.concat([X_Train_0_2, X_Train_1])\n",
    "X_Train_samp3 = pd.concat([X_Train_0_3, X_Train_1])\n",
    "X_Train_samp4 = pd.concat([X_Train_0_4, X_Train_1])\n",
    "X_Train_samp5 = pd.concat([X_Train_0_5, X_Train_1])\n",
    "X_Train_samp6 = pd.concat([X_Train_0_6, X_Train_1])\n",
    "X_Train_samp7 = pd.concat([X_Train_0_7, X_Train_1])\n",
    "X_Train_samp8 = pd.concat([X_Train_0_8, X_Train_1])\n",
    "X_Train_samp9 = pd.concat([X_Train_0_9, X_Train_1])\n",
    "X_Train_samp10 = pd.concat([X_Train_0_10, X_Train_1])\n",
    "X_Train_samp10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tomek undersampling\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "tl = TomekLinks(sampling_strategy='majority')\n",
    "X_Train_res1, Y_Train_res1 = tl.fit_resample(X_Train_samp1.iloc[:,:-1], X_Train_samp1.iloc[:,-1])\n",
    "X_Train_res2, Y_Train_res2 = tl.fit_resample(X_Train_samp2.iloc[:,:-1], X_Train_samp2.iloc[:,-1])\n",
    "X_Train_res3, Y_Train_res3 = tl.fit_resample(X_Train_samp3.iloc[:,:-1], X_Train_samp3.iloc[:,-1])\n",
    "X_Train_res4, Y_Train_res4 = tl.fit_resample(X_Train_samp4.iloc[:,:-1], X_Train_samp4.iloc[:,-1])\n",
    "X_Train_res5, Y_Train_res5 = tl.fit_resample(X_Train_samp5.iloc[:,:-1], X_Train_samp5.iloc[:,-1])\n",
    "X_Train_res6, Y_Train_res6 = tl.fit_resample(X_Train_samp6.iloc[:,:-1], X_Train_samp6.iloc[:,-1])\n",
    "X_Train_res7, Y_Train_res7 = tl.fit_resample(X_Train_samp7.iloc[:,:-1], X_Train_samp7.iloc[:,-1])\n",
    "X_Train_res8, Y_Train_res8 = tl.fit_resample(X_Train_samp8.iloc[:,:-1], X_Train_samp8.iloc[:,-1])\n",
    "X_Train_res9, Y_Train_res9 = tl.fit_resample(X_Train_samp9.iloc[:,:-1], X_Train_samp9.iloc[:,-1])\n",
    "X_Train_res10, Y_Train_res10 = tl.fit_resample(X_Train_samp10.iloc[:,:-1], X_Train_samp10.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test = X_Test.drop('y',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(Y_Train_res1)/len(Y_Train_res1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = Y_Test.to_numpy()\n",
    "bg = pd.DataFrame(data=yt, index=None, columns=['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run series of 10 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run model on group 1\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "est1 = XGBClassifier(eta=0.1, min_child_weight=1, max_depth=4)\n",
    "eval_set = [(X_Test,Y_Test)]\n",
    "est1.fit(X_Train_res1, Y_Train_res1, early_stopping_rounds=10, eval_metric=\"auc\", eval_set=eval_set)\n",
    "\n",
    "print('Test Results')\n",
    "predict_val = est1.predict(X_Test)\n",
    "print(confusion_matrix(Y_Test, predict_val))\n",
    "print(classification_report(Y_Test, predict_val, digits=3))\n",
    "test_preds1 = est1.predict_proba(X_Test)\n",
    "auc_prob = roc_auc_score(Y_Test, test_preds1[:,1])\n",
    "print('AUC prob : ',auc_prob)\n",
    "\n",
    "bg['preds1'] = test_preds1[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group 2\n",
    "est2 = XGBClassifier(eta=0.1, min_child_weight=1, max_depth=4)\n",
    "eval_set = [(X_Test,Y_Test)]\n",
    "est2.fit(X_Train_res2, Y_Train_res2, early_stopping_rounds=10, eval_metric=\"auc\", eval_set=eval_set)\n",
    "\n",
    "print('Train Results')\n",
    "print(est2.score(X_Train_res2, Y_Train_res2))\n",
    "print(recall_score(Y_Train_res2, est2.predict(X_Train_res2)))\n",
    "predict_val = est2.predict(X_Train_res2)\n",
    "auc_val = roc_auc_score(Y_Train_res2, predict_val)\n",
    "print('AUC score : ',auc_val)\n",
    "print(confusion_matrix(Y_Train_res2, predict_val))\n",
    "print(classification_report(Y_Train_res2, predict_val, digits=3))\n",
    "predict_proba_train = est2.predict_proba(X_Train_res2)\n",
    "auc_prob = roc_auc_score(Y_Train_res2, predict_proba_train[:,1])\n",
    "print('AUC prob : ',auc_prob)\n",
    "\n",
    "print('/nTest Results')\n",
    "print(est2.score(X_Test, Y_Test))\n",
    "print(recall_score(Y_Test, est2.predict(X_Test)))\n",
    "predict_val = est2.predict(X_Test)\n",
    "auc_val = roc_auc_score(Y_Test, predict_val)\n",
    "print('AUC score : ',auc_val)\n",
    "print(confusion_matrix(Y_Test, predict_val))\n",
    "print(classification_report(Y_Test, predict_val, digits=3))\n",
    "test_preds2 = est2.predict_proba(X_Test)\n",
    "auc_prob = roc_auc_score(Y_Test, test_preds2[:,1])\n",
    "print('AUC prob : ',auc_prob)\n",
    "\n",
    "bg['preds2'] = test_preds2[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run model on group 3\n",
    "est3 = XGBClassifier(eta=0.1, min_child_weight=1, max_depth=4)\n",
    "eval_set = [(X_Test,Y_Test)]\n",
    "est3.fit(X_Train_res3, Y_Train_res3, early_stopping_rounds=10, eval_metric=\"auc\", eval_set=eval_set)\n",
    "print('Train Results')\n",
    "\n",
    "predict_val = est3.predict(X_Train_res3)\n",
    "print(confusion_matrix(Y_Train_res3, predict_val))\n",
    "print(classification_report(Y_Train_res3, predict_val, digits=3))\n",
    "predict_proba_train = est3.predict_proba(X_Train_res3)\n",
    "auc_prob = roc_auc_score(Y_Train_res3, predict_proba_train[:,1])\n",
    "print('AUC prob : ',auc_prob)\n",
    "\n",
    "print('/nTest Results')\n",
    "predict_val = est3.predict(X_Test)\n",
    "print(confusion_matrix(Y_Test, predict_val))\n",
    "print(classification_report(Y_Test, predict_val, digits=3))\n",
    "test_preds3 = est3.predict_proba(X_Test)\n",
    "auc_prob = roc_auc_score(Y_Test, test_preds3[:,1])\n",
    "print('AUC prob : ',auc_prob)\n",
    "\n",
    "bg['preds3'] = test_preds3[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run model on group 4\n",
    "est4 = XGBClassifier(eta=0.1, min_child_weight=1, max_depth=4)\n",
    "eval_set = [(X_Test,Y_Test)]\n",
    "est4.fit(X_Train_res4, Y_Train_res4, early_stopping_rounds=10, eval_metric=\"auc\", eval_set=eval_set)\n",
    "\n",
    "print('Train Results')\n",
    "\n",
    "predict_val = est4.predict(X_Train_res4)\n",
    "print(confusion_matrix(Y_Train_res4, predict_val))\n",
    "print(classification_report(Y_Train_res4, predict_val, digits=3))\n",
    "predict_proba_train = est4.predict_proba(X_Train_res4)\n",
    "auc_prob = roc_auc_score(Y_Train_res4, predict_proba_train[:,1])\n",
    "print('AUC prob : ',auc_prob)\n",
    "\n",
    "print('/nTest Results')\n",
    "predict_val = est4.predict(X_Test)\n",
    "print(confusion_matrix(Y_Test, predict_val))\n",
    "print(classification_report(Y_Test, predict_val, digits=3))\n",
    "test_preds4 = est4.predict_proba(X_Test)\n",
    "auc_prob = roc_auc_score(Y_Test, test_preds4[:,1])\n",
    "print('AUC prob : ',auc_prob)\n",
    "bg['preds4'] = test_preds4[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run model on group 5\n",
    "est5 = XGBClassifier(eta=0.1, min_child_weight=1, max_depth=4)\n",
    "eval_set = [(X_Test,Y_Test)]\n",
    "est5.fit(X_Train_res5, Y_Train_res5, early_stopping_rounds=10, eval_metric=\"auc\", eval_set=eval_set)\n",
    "\n",
    "print('Test Results')\n",
    "predict_val = est5.predict(X_Test)\n",
    "print(confusion_matrix(Y_Test, predict_val))\n",
    "print(classification_report(Y_Test, predict_val, digits=3))\n",
    "test_preds5 = est5.predict_proba(X_Test)\n",
    "auc_prob = roc_auc_score(Y_Test, test_preds5[:,1])\n",
    "print('AUC prob : ',auc_prob)\n",
    "\n",
    "bg['preds5'] = test_preds5[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run model on group 6\n",
    "est6 = XGBClassifier(eta=0.1, min_child_weight=1, max_depth=4)\n",
    "eval_set = [(X_Test,Y_Test)]\n",
    "est6.fit(X_Train_res6, Y_Train_res6, early_stopping_rounds=10, eval_metric=\"auc\", eval_set=eval_set)\n",
    "\n",
    "print('Test Results')\n",
    "predict_val = est6.predict(X_Test)\n",
    "print(confusion_matrix(Y_Test, predict_val))\n",
    "print(classification_report(Y_Test, predict_val, digits=3))\n",
    "test_preds6 = est6.predict_proba(X_Test)\n",
    "auc_prob = roc_auc_score(Y_Test, test_preds6[:,1])\n",
    "print('AUC prob : ',auc_prob)\n",
    "\n",
    "bg['preds6'] = test_preds6[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group 7\n",
    "est7 = XGBClassifier(eta=0.1, min_child_weight=1, max_depth=4)\n",
    "eval_set = [(X_Test,Y_Test)]\n",
    "est7.fit(X_Train_res7, Y_Train_res7, early_stopping_rounds=10, eval_metric=\"auc\", eval_set=eval_set)\n",
    "\n",
    "print('Test Results')\n",
    "predict_val = est7.predict(X_Test)\n",
    "print(confusion_matrix(Y_Test, predict_val))\n",
    "print(classification_report(Y_Test, predict_val, digits=3))\n",
    "test_preds7 = est7.predict_proba(X_Test)\n",
    "auc_prob = roc_auc_score(Y_Test, test_preds7[:,1])\n",
    "print('AUC prob : ',auc_prob)\n",
    "\n",
    "bg['preds7'] = test_preds7[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group 8\n",
    "est8 = XGBClassifier(eta=0.1, min_child_weight=1, max_depth=4)\n",
    "eval_set = [(X_Test,Y_Test)]\n",
    "est8.fit(X_Train_res8, Y_Train_res8, early_stopping_rounds=10, eval_metric=\"auc\", eval_set=eval_set)\n",
    "\n",
    "print('Test Results')\n",
    "predict_val = est8.predict(X_Test)\n",
    "print(confusion_matrix(Y_Test, predict_val))\n",
    "print(classification_report(Y_Test, predict_val, digits=3))\n",
    "test_preds8 = est8.predict_proba(X_Test)\n",
    "auc_prob = roc_auc_score(Y_Test, test_preds8[:,1])\n",
    "print('AUC prob : ',auc_prob)\n",
    "\n",
    "bg['preds8'] = test_preds8[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group 9\n",
    "est9 = XGBClassifier(eta=0.1, min_child_weight=1, max_depth=4)\n",
    "eval_set = [(X_Test,Y_Test)]\n",
    "est9.fit(X_Train_res9, Y_Train_res9, early_stopping_rounds=10, eval_metric=\"auc\", eval_set=eval_set)\n",
    "\n",
    "print('Test Results')\n",
    "predict_val = est9.predict(X_Test)\n",
    "print(confusion_matrix(Y_Test, predict_val))\n",
    "print(classification_report(Y_Test, predict_val, digits=3))\n",
    "test_preds9 = est9.predict_proba(X_Test)\n",
    "auc_prob = roc_auc_score(Y_Test, test_preds9[:,1])\n",
    "print('AUC prob : ',auc_prob)\n",
    "\n",
    "bg['preds9'] = test_preds9[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group 10\n",
    "est10 = XGBClassifier(eta=0.1, min_child_weight=1, max_depth=4)\n",
    "eval_set = [(X_Test,Y_Test)]\n",
    "est10.fit(X_Train_res10, Y_Train_res10, early_stopping_rounds=10, eval_metric=\"auc\", eval_set=eval_set)\n",
    "\n",
    "print('Test Results')\n",
    "predict_val = est10.predict(X_Test)\n",
    "print(confusion_matrix(Y_Test, predict_val))\n",
    "print(classification_report(Y_Test, predict_val, digits=3))\n",
    "test_preds10 = est10.predict_proba(X_Test)\n",
    "auc_prob = roc_auc_score(Y_Test, test_preds10[:,1])\n",
    "print('AUC prob : ',auc_prob)\n",
    "\n",
    "bg['preds10'] = test_preds10[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'gain'\n",
    "i = est2.get_booster().get_score(importance_type= f)\n",
    "j = pd.Series(i).sort_values(ascending=False)\n",
    "j[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = bg.loc[: , \"preds1\":\"preds10\"]\n",
    "bg['cum_prob'] = col.mean(axis=1)\n",
    "\n",
    "bg['cum_pred'] = np.where(bg['cum_prob'] > 0.5, 1, 0)\n",
    "bg['stdev'] = col.std(axis=1)\n",
    "\n",
    "bg[61:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(bg['y'], bg['cum_pred'], digits=3))\n",
    "auc_prob = roc_auc_score(bg['y'], bg['cum_prob'])\n",
    "print('AUC prob : ',auc_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}